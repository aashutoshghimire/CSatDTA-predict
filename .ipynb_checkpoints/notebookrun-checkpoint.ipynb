{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac189ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from numpy import loadtxt\n",
    "# import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "# from atten import *\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "# from params import parseargs\n",
    "# from datamanager import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from matplotlib.pyplot import cm\n",
    "import argparse\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "# The GPU id to use, usually either \"0\" or \"1\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7276278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Concatenate, concatenate, Reshape\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D\n",
    "\n",
    "# import keras\n",
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow as tf\n",
    "# from keras import backend as K\n",
    "from tensorflow.keras import backend as K\n",
    "# from conv import *\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7a0b7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys, re, math, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "import collections\n",
    "from collections import OrderedDict\n",
    "from matplotlib.pyplot import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e71effdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _conv_layer1d(ip, t_n, f_n, filters, kernel_size, strides=1, padding='same', name=None):\n",
    "    \n",
    "\n",
    "    conv1 = Conv1D(filters, kernel_size, strides=strides, padding=padding,\n",
    "                  use_bias=True, kernel_initializer='glorot_normal', name=name)(ip)\n",
    "    \n",
    "    reshape = Reshape((t_n, 1, filters))(conv1)\n",
    "    \n",
    "    return reshape\n",
    "\n",
    "\n",
    "\n",
    "def _conv_layer1r(ip, t_n, f_n, filters, kernel_size, strides=1, padding='same', name=None):\n",
    "    \n",
    "    reshape1 = Reshape((t_n, f_n))(ip)\n",
    "    \n",
    "\n",
    "    conv1 = Conv1D(filters, kernel_size, strides=strides, padding=padding,\n",
    "                  use_bias=True, kernel_initializer='glorot_normal', name=name)(reshape1)\n",
    "    \n",
    "    reshape2 = Reshape((t_n, 1, filters))(conv1)\n",
    "    \n",
    "    return reshape2\n",
    "\n",
    "\n",
    "def _normalize_depth_vars(depth_k, depth_v, filters):\n",
    "\n",
    "    if type(depth_k) == float:\n",
    "        depth_k = int(filters * depth_k)\n",
    "    else:\n",
    "        depth_k = int(depth_k)\n",
    "\n",
    "    if type(depth_v) == float:\n",
    "        depth_v = int(filters * depth_v)\n",
    "    else:\n",
    "        depth_v = int(depth_v)\n",
    "\n",
    "    return depth_k, depth_v\n",
    "\n",
    "\n",
    "def cindex_score(y_true, y_pred):\n",
    "\n",
    "    g = tf.subtract(tf.expand_dims(y_pred, -1), y_pred)\n",
    "    g = tf.cast(g == 0.0, tf.float32) * 0.5 + tf.cast(g > 0.0, tf.float32)\n",
    "\n",
    "    f = tf.subtract(tf.expand_dims(y_true, -1), y_true) > 0.0\n",
    "    f = tf.compat.v1.matrix_band_part(tf.cast(f, tf.float32), -1, 0)\n",
    "\n",
    "    g = tf.reduce_sum(tf.multiply(g, f))\n",
    "    f = tf.reduce_sum(f)\n",
    "\n",
    "    return tf.where(tf.equal(g, 0), 0.0, g/f) #select\n",
    "\n",
    "\n",
    "\n",
    "class AttentionAugmentation2D(Layer):\n",
    "\n",
    "    def __init__(self, depth_k, depth_v, num_heads, relative=True, **kwargs):\n",
    "\n",
    "        super(AttentionAugmentation2D, self).__init__(**kwargs)\n",
    "\n",
    "        if depth_k % num_heads != 0:\n",
    "            raise ValueError('`depth_k` (%d) should be divisible by `num_heads` (%d)' % (\n",
    "                depth_k, num_heads))\n",
    "\n",
    "        if depth_v % num_heads != 0:\n",
    "            raise ValueError('`depth_v` (%d) should be divisible by `num_heads` (%d)' % (\n",
    "                depth_v, num_heads))\n",
    "\n",
    "        if depth_k // num_heads < 1.:\n",
    "            raise ValueError('depth_k / num_heads cannot be less than 1 ! '\n",
    "                             'Given depth_k = %d, num_heads = %d' % (\n",
    "                             depth_k, num_heads))\n",
    "\n",
    "        if depth_v // num_heads < 1.:\n",
    "            raise ValueError('depth_v / num_heads cannot be less than 1 ! '\n",
    "                             'Given depth_v = %d, num_heads = %d' % (\n",
    "                                 depth_v, num_heads))\n",
    "\n",
    "        self.depth_k = depth_k\n",
    "        self.depth_v = depth_v\n",
    "        self.num_heads = num_heads\n",
    "        self.relative = relative\n",
    "\n",
    "        self.axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self._shape = input_shape\n",
    "\n",
    "        # normalize the format of depth_v and depth_k\n",
    "        self.depth_k, self.depth_v = _normalize_depth_vars(self.depth_k, self.depth_v,\n",
    "                                                           input_shape)\n",
    "\n",
    "        if self.axis == 1:\n",
    "            _, channels, height, width = input_shape\n",
    "        else:\n",
    "            _, height, width, channels = input_shape\n",
    "\n",
    "        if self.relative:\n",
    "            dk_per_head = self.depth_k // self.num_heads\n",
    "            \n",
    "            # print(dk_per_head)\n",
    "\n",
    "            if dk_per_head == 0:\n",
    "                print('dk per head', dk_per_head)\n",
    "\n",
    "            self.key_relative_w = self.add_weight('key_rel_w',\n",
    "                                                  shape=tf.TensorShape([2 * width - 1, dk_per_head]),\n",
    "                                                  initializer=initializers.RandomNormal(stddev=dk_per_head ** -0.5))\n",
    "            # 2 * width - 1\n",
    "\n",
    "            self.key_relative_h = self.add_weight('key_rel_h',\n",
    "                                                  shape=tf.TensorShape([2 * height - 1, dk_per_head]),\n",
    "                                                  initializer=initializers.RandomNormal(stddev=dk_per_head ** -0.5))\n",
    "            # 2 * height - 1\n",
    "\n",
    "        else:\n",
    "            self.key_relative_w = None\n",
    "            self.key_relative_h = None\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        if self.axis == 1:\n",
    "            # If channels first, force it to be channels last for these ops\n",
    "            inputs = K.permute_dimensions(inputs, [0, 2, 3, 1])\n",
    "\n",
    "        q, k, v = tf.split(inputs, [self.depth_k, self.depth_k, self.depth_v], axis=-1)\n",
    "\n",
    "        q = self.split_heads_2d(q)\n",
    "        k = self.split_heads_2d(k)\n",
    "        v = self.split_heads_2d(v)\n",
    "\n",
    "        # scale query\n",
    "        depth_k_heads = self.depth_k / self.num_heads\n",
    "        q *= (depth_k_heads ** -0.5)\n",
    "\n",
    "        qk_shape = [self._batch, self.num_heads, self._height * self._width, self.depth_k // self.num_heads]\n",
    "        v_shape = [self._batch, self.num_heads, self._height * self._width, self.depth_v // self.num_heads]\n",
    "        flat_q = K.reshape(q, tf.stack(qk_shape))\n",
    "        flat_k = K.reshape(k, tf.stack(qk_shape))\n",
    "        flat_v = K.reshape(v, tf.stack(v_shape))\n",
    "\n",
    "        # [Batch, num_heads, HW, HW]\n",
    "        logits = tf.matmul(flat_q, flat_k, transpose_b=True)\n",
    "\n",
    "        # Apply relative encodings\n",
    "        if self.relative:\n",
    "            h_rel_logits, w_rel_logits = self.relative_logits(q)\n",
    "            logits += h_rel_logits\n",
    "            logits += w_rel_logits\n",
    "\n",
    "        weights = K.softmax(logits, axis=-1)\n",
    "        attn_out = tf.matmul(weights, flat_v)\n",
    "\n",
    "        attn_out_shape = [self._batch, self.num_heads, self._height, self._width, self.depth_v // self.num_heads]\n",
    "        attn_out_shape = tf.stack(attn_out_shape)\n",
    "        attn_out = K.reshape(attn_out, attn_out_shape)\n",
    "        attn_out = self.combine_heads_2d(attn_out)\n",
    "        # [batch, height, width, depth_v]\n",
    "\n",
    "        if self.axis == 1:\n",
    "            # return to [batch, depth_v, height, width] for channels first\n",
    "            attn_out = K.permute_dimensions(attn_out, [0, 3, 1, 2])\n",
    "\n",
    "        return attn_out\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_shape = list(input_shape)\n",
    "        output_shape[self.axis] = self.depth_v\n",
    "        return tuple(output_shape)\n",
    "\n",
    "    def split_heads_2d(self, ip):\n",
    "        tensor_shape = K.shape(ip)\n",
    "\n",
    "        # batch, height, width, channels for axis = -1\n",
    "        tensor_shape = [tensor_shape[i] for i in range(len(self._shape))]\n",
    "\n",
    "        batch = tensor_shape[0]\n",
    "        height = tensor_shape[1]\n",
    "        width = tensor_shape[2]\n",
    "        channels = tensor_shape[3]\n",
    "\n",
    "        # Save the spatial tensor dimensions\n",
    "        self._batch = batch\n",
    "        self._height = height\n",
    "        self._width = width\n",
    "\n",
    "        ret_shape = tf.stack([batch, height, width,  self.num_heads, channels // self.num_heads])\n",
    "        split = K.reshape(ip, ret_shape)\n",
    "        transpose_axes = (0, 3, 1, 2, 4)\n",
    "        split = K.permute_dimensions(split, transpose_axes)\n",
    "\n",
    "        return split\n",
    "\n",
    "    def relative_logits(self, q):\n",
    "        shape = K.shape(q)\n",
    "        # [batch, num_heads, H, W, depth_v]\n",
    "        shape = [shape[i] for i in range(5)]\n",
    "\n",
    "        height = shape[2]\n",
    "        width = shape[3]\n",
    "\n",
    "        rel_logits_w = self.relative_logits_1d(q, self.key_relative_w, height, width,\n",
    "                                               transpose_mask=[0, 1, 2, 4, 3, 5])\n",
    "\n",
    "        rel_logits_h = self.relative_logits_1d(\n",
    "            K.permute_dimensions(q, [0, 1, 3, 2, 4]),\n",
    "            self.key_relative_h, width, height,\n",
    "            transpose_mask=[0, 1, 4, 2, 5, 3])\n",
    "\n",
    "        return rel_logits_h, rel_logits_w\n",
    "\n",
    "    def relative_logits_1d(self, q, rel_k, H, W, transpose_mask):\n",
    "        rel_logits = tf.einsum('bhxyd,md->bhxym', q, rel_k)\n",
    "        rel_logits = K.reshape(rel_logits, [-1, self.num_heads * H, W, 2 * W - 1])\n",
    "        rel_logits = self.rel_to_abs(rel_logits)\n",
    "        rel_logits = K.reshape(rel_logits, [-1, self.num_heads, H, W, W])\n",
    "        rel_logits = K.expand_dims(rel_logits, axis=3)\n",
    "        rel_logits = K.tile(rel_logits, [1, 1, 1, H, 1, 1])\n",
    "        rel_logits = K.permute_dimensions(rel_logits, transpose_mask)\n",
    "        rel_logits = K.reshape(rel_logits, [-1, self.num_heads, H * W, H * W])\n",
    "        return rel_logits\n",
    "\n",
    "    def rel_to_abs(self, x):\n",
    "        shape = K.shape(x)\n",
    "        shape = [shape[i] for i in range(3)]\n",
    "        B, Nh, L, = shape\n",
    "        # col_pad = K.zeros(K.stack([B, Nh, L, 1]))\n",
    "        col_pad = tf.zeros(tf.stack([B, Nh, L, 1]))\n",
    "        # col_pad = tf.zeros([B, Nh, L, 1])\n",
    "\n",
    "        x = K.concatenate([x, col_pad], axis=3)\n",
    "        flat_x = K.reshape(x, [B, Nh, L * 2 * L])\n",
    "        flat_pad = tf.zeros(tf.stack([B, Nh, L - 1]))\n",
    "        flat_x_padded = K.concatenate([flat_x, flat_pad], axis=2)\n",
    "        final_x = K.reshape(flat_x_padded, [B, Nh, L + 1, 2 * L - 1])\n",
    "        final_x = final_x[:, :, :L, L - 1:]\n",
    "        return final_x\n",
    "\n",
    "    def combine_heads_2d(self, inputs):\n",
    "        # [batch, num_heads, height, width, depth_v // num_heads]\n",
    "        transposed = K.permute_dimensions(inputs, [0, 2, 3, 1, 4])\n",
    "        # [batch, height, width, num_heads, depth_v // num_heads]\n",
    "        shape = K.shape(transposed)\n",
    "        shape = [shape[i] for i in range(5)]\n",
    "\n",
    "        a, b = shape[-2:]\n",
    "        ret_shape = tf.stack(shape[:-2] + [a * b])\n",
    "        # [batch, height, width, depth_v]\n",
    "        return K.reshape(transposed, ret_shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'depth_k': self.depth_k,\n",
    "            'depth_v': self.depth_v,\n",
    "            'num_heads': self.num_heads,\n",
    "            'relative': self.relative,\n",
    "        }\n",
    "        base_config = super(AttentionAugmentation2D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "def augmented_conv1d(ip, shape, filters, kernel_size=3, strides=1, padding = 'same',\n",
    "                     depth_k=0.2, depth_v=0.2, num_heads=2, relative_encodings=True):\n",
    "    \n",
    "    if type(kernel_size) == int:\n",
    "        pass\n",
    "    else:\n",
    "        kernel_size = kernel_size[0]\n",
    "        \n",
    "    if type(strides) == int:\n",
    "        pass\n",
    "    else:\n",
    "        strides = strides[0]\n",
    "        \n",
    "    t_n = shape[0]\n",
    "    f_n = shape[1]\n",
    "        \n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    depth_k, depth_v = _normalize_depth_vars(depth_k, depth_v, filters)\n",
    "\n",
    "\n",
    "    conv_out = _conv_layer1d(ip, t_n, f_n, filters - depth_v, kernel_size, strides, padding = 'same')\n",
    "\n",
    "    # Augmented Attention Block\n",
    "    qkv_conv = _conv_layer1d(ip, t_n, f_n,  2 * depth_k + depth_v, 1, strides, padding = 'same')\n",
    "    attn_out = AttentionAugmentation2D(depth_k, depth_v, num_heads, relative_encodings)(qkv_conv)\n",
    "    attn_out = _conv_layer1r(attn_out, t_n, depth_v,  depth_v, 1, strides, padding = 'same')\n",
    "    \n",
    "    output = tf.keras.layers.concatenate([conv_out, attn_out], axis=-1)\n",
    "   \n",
    "    reshape = Reshape((t_n, filters))(output)\n",
    "\n",
    "    return reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee787a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARPROTSET = { \"A\": 1, \"C\": 2, \"B\": 3, \"E\": 4, \"D\": 5, \"G\": 6, \n",
    "\t\t\t\t\"F\": 7, \"I\": 8, \"H\": 9, \"K\": 10, \"M\": 11, \"L\": 12, \n",
    "\t\t\t\t\"O\": 13, \"N\": 14, \"Q\": 15, \"P\": 16, \"S\": 17, \"R\": 18, \n",
    "\t\t\t\t\"U\": 19, \"T\": 20, \"W\": 21, \n",
    "\t\t\t\t\"V\": 22, \"Y\": 23, \"X\": 24, \n",
    "\t\t\t\t\"Z\": 25 }\n",
    "\n",
    "CHARPROTLEN = 25\n",
    "\n",
    "CHARCANSMISET = { \"#\": 1, \"%\": 2, \")\": 3, \"(\": 4, \"+\": 5, \"-\": 6, \n",
    "\t\t\t \".\": 7, \"1\": 8, \"0\": 9, \"3\": 10, \"2\": 11, \"5\": 12, \n",
    "\t\t\t \"4\": 13, \"7\": 14, \"6\": 15, \"9\": 16, \"8\": 17, \"=\": 18, \n",
    "\t\t\t \"A\": 19, \"C\": 20, \"B\": 21, \"E\": 22, \"D\": 23, \"G\": 24,\n",
    "\t\t\t \"F\": 25, \"I\": 26, \"H\": 27, \"K\": 28, \"M\": 29, \"L\": 30, \n",
    "\t\t\t \"O\": 31, \"N\": 32, \"P\": 33, \"S\": 34, \"R\": 35, \"U\": 36, \n",
    "\t\t\t \"T\": 37, \"W\": 38, \"V\": 39, \"Y\": 40, \"[\": 41, \"Z\": 42, \n",
    "\t\t\t \"]\": 43, \"_\": 44, \"a\": 45, \"c\": 46, \"b\": 47, \"e\": 48, \n",
    "\t\t\t \"d\": 49, \"g\": 50, \"f\": 51, \"i\": 52, \"h\": 53, \"m\": 54, \n",
    "\t\t\t \"l\": 55, \"o\": 56, \"n\": 57, \"s\": 58, \"r\": 59, \"u\": 60,\n",
    "\t\t\t \"t\": 61, \"y\": 62}\n",
    "\n",
    "CHARCANSMILEN = 62\n",
    "\n",
    "CHARISOSMISET = {\"#\": 29, \"%\": 30, \")\": 31, \"(\": 1, \"+\": 32, \"-\": 33, \"/\": 34, \".\": 2, \n",
    "\t\t\t\t\"1\": 35, \"0\": 3, \"3\": 36, \"2\": 4, \"5\": 37, \"4\": 5, \"7\": 38, \"6\": 6, \n",
    "\t\t\t\t\"9\": 39, \"8\": 7, \"=\": 40, \"A\": 41, \"@\": 8, \"C\": 42, \"B\": 9, \"E\": 43, \n",
    "\t\t\t\t\"D\": 10, \"G\": 44, \"F\": 11, \"I\": 45, \"H\": 12, \"K\": 46, \"M\": 47, \"L\": 13, \n",
    "\t\t\t\t\"O\": 48, \"N\": 14, \"P\": 15, \"S\": 49, \"R\": 16, \"U\": 50, \"T\": 17, \"W\": 51, \n",
    "\t\t\t\t\"V\": 18, \"Y\": 52, \"[\": 53, \"Z\": 19, \"]\": 54, \"\\\\\": 20, \"a\": 55, \"c\": 56, \n",
    "\t\t\t\t\"b\": 21, \"e\": 57, \"d\": 22, \"g\": 58, \"f\": 23, \"i\": 59, \"h\": 24, \"m\": 60, \n",
    "\t\t\t\t\"l\": 25, \"o\": 61, \"n\": 26, \"s\": 62, \"r\": 27, \"u\": 63, \"t\": 28, \"y\": 64}\n",
    "\n",
    "CHARISOSMILEN = 64\n",
    "# def one_hot_smiles(line, MAX_SMI_LEN, smi_ch_ind):\n",
    "# \tX = np.zeros((MAX_SMI_LEN, len(smi_ch_ind))) #+1\n",
    "\n",
    "# \tfor i, ch in enumerate(line[:MAX_SMI_LEN]):\n",
    "# \t\tX[i, (smi_ch_ind[ch]-1)] = 1 \n",
    "\n",
    "# \treturn X #.tolist()\n",
    "\n",
    "# def one_hot_sequence(line, MAX_SEQ_LEN, smi_ch_ind):\n",
    "# \tX = np.zeros((MAX_SEQ_LEN, len(smi_ch_ind))) \n",
    "# \tfor i, ch in enumerate(line[:MAX_SEQ_LEN]):\n",
    "# \t\tX[i, (smi_ch_ind[ch])-1] = 1\n",
    "\n",
    "# \treturn X #.tolist()\n",
    "\n",
    "\n",
    "def label_smiles(line, MAX_SMI_LEN, smi_ch_ind):\n",
    "\tX = np.zeros(MAX_SMI_LEN)\n",
    "\tfor i, ch in enumerate(line[:MAX_SMI_LEN]): #\tx, smi_ch_ind, y\n",
    "\t\tX[i] = smi_ch_ind[ch]\n",
    "\n",
    "\treturn X #.tolist()\n",
    "\n",
    "def label_sequence(line, MAX_SEQ_LEN, smi_ch_ind):\n",
    "\tX = np.zeros(MAX_SEQ_LEN)\n",
    "\n",
    "\tfor i, ch in enumerate(line[:MAX_SEQ_LEN]):\n",
    "\t\tX[i] = smi_ch_ind[ch]\n",
    "\n",
    "\treturn X #.tolist()\n",
    "\n",
    "\n",
    "class DataSet(object):\n",
    "  def __init__(self, seqlen, smilen, need_shuffle = False):\n",
    "    self.SEQLEN = seqlen\n",
    "    self.SMILEN = smilen\n",
    "    #self.NCLASSES = n_classes\n",
    "    self.charseqset = CHARPROTSET\n",
    "    self.charseqset_size = CHARPROTLEN\n",
    "\n",
    "    self.charsmiset = CHARISOSMISET ###HERE CAN BE EDITED\n",
    "    self.charsmiset_size = CHARISOSMILEN\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def parse_data(self, smileStr, proteinSeq): \n",
    "    # print(\"Read %s start\" % fpath)\n",
    "\n",
    "    XD = []\n",
    "    XT = []\n",
    "    XD.append(label_smiles(smileStr, self.SMILEN, self.charsmiset))\n",
    "    XT.append(label_sequence(proteinSeq, self.SEQLEN, self.charseqset))\n",
    "  \n",
    "    return XD, XT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab2e0bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_interaction_pairs(XD, XT):\n",
    "    drugs = []\n",
    "    targets = []\n",
    "\n",
    "    drug = XD[0]\n",
    "    drugs.append(drug)\n",
    "\n",
    "    target=XT[0]\n",
    "    targets.append(target)\n",
    "\n",
    "    drug_data = np.stack(drugs)\n",
    "    target_data = np.stack(targets)\n",
    "    return drug_data,target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7b65c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(smileStr, proteinSeq):\n",
    "    if(smileStr == None):\n",
    "      return('Simile input is null')\n",
    "    if(proteinSeq == None):\n",
    "      return('Protein Seq input is null')\n",
    "    dependencies = {\n",
    "      'cindex_score': cindex_score,\n",
    "      'AttentionAugmentation2D': AttentionAugmentation2D\n",
    "    }\n",
    "    model = load_model('data/model.h5', custom_objects=dependencies)\n",
    "    max_seq_len  = 1000\n",
    "    max_smi_len = 100\n",
    "    dataset = DataSet(\n",
    "                  seqlen = max_seq_len,\n",
    "                  smilen = max_smi_len,\n",
    "                  need_shuffle = False )\n",
    "    \n",
    "    XD, XT = dataset.parse_data(smileStr, proteinSeq)\n",
    "\n",
    "    val_drugs, val_prots = prepare_interaction_pairs(XD, XT)\n",
    "    # val_drugs, val_prots, val_Y = prepare_interaction_pairs(XD, XT,  Y, terows, tecols)\n",
    "\n",
    "    predicted_labels = model.predict([np.array(val_drugs), np.array(val_prots)])[0][0] \n",
    "    return (predicted_labels)\n",
    "    # print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf163a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 11:25:03.172080: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-07-14 11:25:03.360582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:04:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2022-07-14 11:25:03.360868: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-07-14 11:25:03.363485: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-07-14 11:25:03.365860: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-07-14 11:25:03.366223: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-07-14 11:25:03.369045: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-07-14 11:25:03.370791: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-07-14 11:25:03.377034: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-07-14 11:25:03.384035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
      "2022-07-14 11:25:03.384969: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2022-07-14 11:25:03.577152: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400005000 Hz\n",
      "2022-07-14 11:25:03.594723: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559a32ec8bd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-07-14 11:25:03.594756: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-07-14 11:25:03.971918: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559a331391d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-07-14 11:25:03.971963: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN Xp, Compute Capability 6.1\n",
      "2022-07-14 11:25:03.975357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:04:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2022-07-14 11:25:03.975423: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-07-14 11:25:03.975445: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-07-14 11:25:03.975464: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-07-14 11:25:03.975483: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-07-14 11:25:03.975502: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-07-14 11:25:03.975521: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-07-14 11:25:03.975540: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-07-14 11:25:03.981514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
      "2022-07-14 11:25:03.981566: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-07-14 11:25:03.985371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-07-14 11:25:03.985389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
      "2022-07-14 11:25:03.985400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
      "2022-07-14 11:25:03.995052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11446 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:04:00.0, compute capability: 6.1)\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_10100/1999492015.py\", line 4, in <module>\n",
      "    response = predict(smileStr, proteinSeq)\n",
      "  File \"/tmp/ipykernel_10100/3085688787.py\", line 10, in predict\n",
      "    model = load_model('data/model.h5', custom_objects=dependencies)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\", line 146, in load_model\n",
      "    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\", line 168, in load_model_from_hdf5\n",
      "    custom_objects=custom_objects)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/model_config.py\", line 55, in model_from_config\n",
      "    return deserialize(config, custom_objects=custom_objects)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/serialization.py\", line 106, in deserialize\n",
      "    printable_module_name='layer')\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\", line 303, in deserialize_keras_object\n",
      "    list(custom_objects.items())))\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 937, in from_config\n",
      "    config, custom_objects)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 1903, in reconstruct_from_config\n",
      "    process_node(layer, node_data)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 1851, in process_node\n",
      "    output_tensors = layer(input_tensors, **kwargs)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 748, in __call__\n",
      "    self._maybe_build(inputs)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 2116, in _maybe_build\n",
      "    self.build(input_shapes)\n",
      "  File \"/tmp/ipykernel_10100/4219375979.py\", line 109, in build\n",
      "    initializer=initializers.RandomNormal(stddev=dk_per_head ** -0.5))\n",
      "NameError: name 'initializers' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_10100/1999492015.py\", line 4, in <module>\n",
      "    response = predict(smileStr, proteinSeq)\n",
      "  File \"/tmp/ipykernel_10100/3085688787.py\", line 10, in predict\n",
      "    model = load_model('data/model.h5', custom_objects=dependencies)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\", line 146, in load_model\n",
      "    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\", line 168, in load_model_from_hdf5\n",
      "    custom_objects=custom_objects)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/model_config.py\", line 55, in model_from_config\n",
      "    return deserialize(config, custom_objects=custom_objects)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/serialization.py\", line 106, in deserialize\n",
      "    printable_module_name='layer')\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\", line 303, in deserialize_keras_object\n",
      "    list(custom_objects.items())))\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 937, in from_config\n",
      "    config, custom_objects)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 1903, in reconstruct_from_config\n",
      "    process_node(layer, node_data)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 1851, in process_node\n",
      "    output_tensors = layer(input_tensors, **kwargs)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 748, in __call__\n",
      "    self._maybe_build(inputs)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 2116, in _maybe_build\n",
      "    self.build(input_shapes)\n",
      "  File \"/tmp/ipykernel_10100/4219375979.py\", line 109, in build\n",
      "    initializer=initializers.RandomNormal(stddev=dk_per_head ** -0.5))\n",
      "NameError: name 'initializers' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_10100/1999492015.py\", line 4, in <module>\n",
      "    response = predict(smileStr, proteinSeq)\n",
      "  File \"/tmp/ipykernel_10100/3085688787.py\", line 10, in predict\n",
      "    model = load_model('data/model.h5', custom_objects=dependencies)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\", line 146, in load_model\n",
      "    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\", line 168, in load_model_from_hdf5\n",
      "    custom_objects=custom_objects)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/model_config.py\", line 55, in model_from_config\n",
      "    return deserialize(config, custom_objects=custom_objects)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/serialization.py\", line 106, in deserialize\n",
      "    printable_module_name='layer')\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\", line 303, in deserialize_keras_object\n",
      "    list(custom_objects.items())))\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 937, in from_config\n",
      "    config, custom_objects)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 1903, in reconstruct_from_config\n",
      "    process_node(layer, node_data)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 1851, in process_node\n",
      "    output_tensors = layer(input_tensors, **kwargs)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 748, in __call__\n",
      "    self._maybe_build(inputs)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 2116, in _maybe_build\n",
      "    self.build(input_shapes)\n",
      "  File \"/tmp/ipykernel_10100/4219375979.py\", line 109, in build\n",
      "    initializer=initializers.RandomNormal(stddev=dk_per_head ** -0.5))\n",
      "NameError: name 'initializers' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3186, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3396, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1143, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/site-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"/home/ashutosh/anaconda3/envs/nokeras/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    }
   ],
   "source": [
    "#the following is test value for smile and pretein seq. You can change the values or send externally.\n",
    "proteinSeq = 'MTVKTEAAKGTLTYSRMRGMVAILIAFMKQRRMGLNDFIQKIANNSYACKHPEVQSILKISQPQEPELMNANPSPPPSPSQQINLGPSSNPHAKPSDFHFLKVIGKGSFGKVLLARHKAEEVFYAVKVLQKKAILKKKEEKHIMSERNVLLKNVKHPFLVGLHFSFQTADKLYFVLDYINGGELFYHLQRERCFLEPRARFYAAEIASALGYLHSLNIVYRDLKPENILLDSQGHIVLTDFGLCKENIEHNSTTSTFCGTPEYLAPEVLHKQPYDRTVDWWCLGAVLYEMLYGLPPFYSRNTAEMYDNILNKPLQLKPNITNSARHLLEGLLQKDRTKRLGAKDDFMEIKSHVFFSLINWDDLINKKITPPFNPNVSGPNDLRHFDPEFTEEPVPNSIGKSPDSVLVTASVKEAAEAFLGFSYAPPTDSFL'\n",
    "smileStr = 'CC1CC=CC(=O)CCCCCC2=CC(=CC(=C2C(=O)O1)O)OC'\n",
    "response = predict(smileStr, proteinSeq)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9419f1bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fca051",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nokeras]",
   "language": "python",
   "name": "conda-env-nokeras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
