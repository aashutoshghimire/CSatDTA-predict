{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28dca6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "# The GPU id to use, usually either \"0\" or \"1\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc205393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Layer\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Concatenate, concatenate, Reshape\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D\n",
    "\n",
    "\n",
    "\n",
    "from keras import initializers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _conv_layer1d(ip, t_n, f_n, filters, kernel_size, strides=1, padding='same', name=None):\n",
    "    \n",
    "\n",
    "    conv1 = Conv1D(filters, kernel_size, strides=strides, padding=padding,\n",
    "                  use_bias=True, kernel_initializer='glorot_normal', name=name)(ip)\n",
    "    \n",
    "    reshape = Reshape((t_n, 1, filters))(conv1)\n",
    "    \n",
    "    return reshape\n",
    "\n",
    "\n",
    "\n",
    "def _conv_layer1r(ip, t_n, f_n, filters, kernel_size, strides=1, padding='same', name=None):\n",
    "    \n",
    "    reshape1 = Reshape((t_n, f_n))(ip)\n",
    "    \n",
    "\n",
    "    conv1 = Conv1D(filters, kernel_size, strides=strides, padding=padding,\n",
    "                  use_bias=True, kernel_initializer='glorot_normal', name=name)(reshape1)\n",
    "    \n",
    "    reshape2 = Reshape((t_n, 1, filters))(conv1)\n",
    "    \n",
    "    return reshape2\n",
    "\n",
    "\n",
    "def _normalize_depth_vars(depth_k, depth_v, filters):\n",
    "    \"\"\"\n",
    "    Accepts depth_k and depth_v as either floats or integers\n",
    "    and normalizes them to integers.\n",
    "    Args:\n",
    "        depth_k: float or int.\n",
    "        depth_v: float or int.\n",
    "        filters: number of output filters.\n",
    "    Returns:\n",
    "        depth_k, depth_v as integers.\n",
    "    \"\"\"\n",
    "\n",
    "    if type(depth_k) == float:\n",
    "        depth_k = int(filters * depth_k)\n",
    "    else:\n",
    "        depth_k = int(depth_k)\n",
    "\n",
    "    if type(depth_v) == float:\n",
    "        depth_v = int(filters * depth_v)\n",
    "    else:\n",
    "        depth_v = int(depth_v)\n",
    "\n",
    "    return depth_k, depth_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "089f9b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cindex_score(y_true, y_pred):\n",
    "\n",
    "    g = tf.subtract(tf.expand_dims(y_pred, -1), y_pred)\n",
    "    g = tf.cast(g == 0.0, tf.float32) * 0.5 + tf.cast(g > 0.0, tf.float32)\n",
    "\n",
    "    f = tf.subtract(tf.expand_dims(y_true, -1), y_true) > 0.0\n",
    "    f = tf.compat.v1.matrix_band_part(tf.cast(f, tf.float32), -1, 0)\n",
    "\n",
    "    g = tf.reduce_sum(tf.multiply(g, f))\n",
    "    f = tf.reduce_sum(f)\n",
    "\n",
    "    return tf.where(tf.equal(g, 0), 0.0, g/f) #select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48fb7496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cindex(Y, P):\n",
    "#     sys.exit()\n",
    "    summ = 0\n",
    "    pair = 0\n",
    "    \n",
    "    for i in range(1, len(Y)):\n",
    "        for j in range(0, i):\n",
    "            if i is not j:\n",
    "                if(Y[i] > Y[j]):\n",
    "                    pair +=1\n",
    "                    summ +=  1* (P[i] > P[j]) + 0.5 * (P[i] == P[j])\n",
    "        \n",
    "            \n",
    "    if pair != 0:\n",
    "        return summ/pair\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11202463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Layer\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "# from conv import *\n",
    "from keras.layers import Reshape\n",
    "from keras import initializers\n",
    "\n",
    "## ######################## ##\n",
    "#\n",
    "#  AttentionAugmentation2D Class\n",
    "#\n",
    "## ######################## ## \n",
    "\n",
    "class AttentionAugmentation2D(Layer):\n",
    "\n",
    "    def __init__(self, depth_k, depth_v, num_heads, relative=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Applies attention augmentation on a convolutional layer\n",
    "        output.\n",
    "        Args:\n",
    "            depth_k: float or int. Number of filters for k.\n",
    "            Computes the number of filters for `v`.\n",
    "            If passed as float, computed as `filters * depth_k`.\n",
    "        depth_v: float or int. Number of filters for v.\n",
    "            Computes the number of filters for `k`.\n",
    "            If passed as float, computed as `filters * depth_v`.\n",
    "        num_heads: int. Number of attention heads.\n",
    "            Must be set such that `depth_k // num_heads` is > 0.\n",
    "        relative: bool, whether to use relative encodings.\n",
    "        Raises:\n",
    "            ValueError: if depth_v or depth_k is not divisible by\n",
    "                num_heads.\n",
    "        Returns:\n",
    "            Output tensor of shape\n",
    "            -   [Batch, Height, Width, Depth_V] if\n",
    "                channels_last data format.\n",
    "            -   [Batch, Depth_V, Height, Width] if\n",
    "                channels_first data format.\n",
    "        \"\"\"\n",
    "        super(AttentionAugmentation2D, self).__init__(**kwargs)\n",
    "\n",
    "        if depth_k % num_heads != 0:\n",
    "            raise ValueError('`depth_k` (%d) is not divisible by `num_heads` (%d)' % (\n",
    "                depth_k, num_heads))\n",
    "\n",
    "        if depth_v % num_heads != 0:\n",
    "            raise ValueError('`depth_v` (%d) is not divisible by `num_heads` (%d)' % (\n",
    "                depth_v, num_heads))\n",
    "\n",
    "        if depth_k // num_heads < 1.:\n",
    "            raise ValueError('depth_k / num_heads cannot be less than 1 ! '\n",
    "                             'Given depth_k = %d, num_heads = %d' % (\n",
    "                             depth_k, num_heads))\n",
    "\n",
    "        if depth_v // num_heads < 1.:\n",
    "            raise ValueError('depth_v / num_heads cannot be less than 1 ! '\n",
    "                             'Given depth_v = %d, num_heads = %d' % (\n",
    "                                 depth_v, num_heads))\n",
    "\n",
    "        self.depth_k = depth_k\n",
    "        self.depth_v = depth_v\n",
    "        self.num_heads = num_heads\n",
    "        self.relative = relative\n",
    "\n",
    "        self.axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self._shape = input_shape\n",
    "\n",
    "        # normalize the format of depth_v and depth_k\n",
    "        self.depth_k, self.depth_v = _normalize_depth_vars(self.depth_k, self.depth_v,\n",
    "                                                           input_shape)\n",
    "\n",
    "        if self.axis == 1:\n",
    "            _, channels, height, width = input_shape\n",
    "        else:\n",
    "            _, height, width, channels = input_shape\n",
    "\n",
    "        if self.relative:\n",
    "            dk_per_head = self.depth_k // self.num_heads\n",
    "            \n",
    "            # print(dk_per_head)\n",
    "\n",
    "            if dk_per_head == 0:\n",
    "                print('dk per head', dk_per_head)\n",
    "\n",
    "            self.key_relative_w = self.add_weight('key_rel_w',\n",
    "                                                  shape=tf.TensorShape([2 * width - 1, dk_per_head]),\n",
    "                                                  initializer=initializers.RandomNormal(stddev=dk_per_head ** -0.5))\n",
    "            # 2 * width - 1\n",
    "\n",
    "            self.key_relative_h = self.add_weight('key_rel_h',\n",
    "                                                  shape=tf.TensorShape([2 * height - 1, dk_per_head]),\n",
    "                                                  initializer=initializers.RandomNormal(stddev=dk_per_head ** -0.5))\n",
    "            # 2 * height - 1\n",
    "\n",
    "        else:\n",
    "            self.key_relative_w = None\n",
    "            self.key_relative_h = None\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        if self.axis == 1:\n",
    "            # If channels first, force it to be channels last for these ops\n",
    "            inputs = K.permute_dimensions(inputs, [0, 2, 3, 1])\n",
    "\n",
    "        q, k, v = tf.split(inputs, [self.depth_k, self.depth_k, self.depth_v], axis=-1)\n",
    "\n",
    "        q = self.split_heads_2d(q)\n",
    "        k = self.split_heads_2d(k)\n",
    "        v = self.split_heads_2d(v)\n",
    "\n",
    "        # scale query\n",
    "        depth_k_heads = self.depth_k / self.num_heads\n",
    "        q *= (depth_k_heads ** -0.5)\n",
    "\n",
    "        # [Batch, num_heads, height * width, depth_k or depth_v] if axis == -1\n",
    "        qk_shape = [self._batch, self.num_heads, self._height * self._width, self.depth_k // self.num_heads]\n",
    "        v_shape = [self._batch, self.num_heads, self._height * self._width, self.depth_v // self.num_heads]\n",
    "        flat_q = K.reshape(q, K.stack(qk_shape))\n",
    "        flat_k = K.reshape(k, K.stack(qk_shape))\n",
    "        flat_v = K.reshape(v, K.stack(v_shape))\n",
    "\n",
    "        # [Batch, num_heads, HW, HW]\n",
    "        logits = tf.matmul(flat_q, flat_k, transpose_b=True)\n",
    "\n",
    "        # Apply relative encodings\n",
    "        if self.relative:\n",
    "            h_rel_logits, w_rel_logits = self.relative_logits(q)\n",
    "            logits += h_rel_logits\n",
    "            logits += w_rel_logits\n",
    "\n",
    "        weights = K.softmax(logits, axis=-1)\n",
    "        attn_out = tf.matmul(weights, flat_v)\n",
    "\n",
    "        attn_out_shape = [self._batch, self.num_heads, self._height, self._width, self.depth_v // self.num_heads]\n",
    "        attn_out_shape = K.stack(attn_out_shape)\n",
    "        attn_out = K.reshape(attn_out, attn_out_shape)\n",
    "        attn_out = self.combine_heads_2d(attn_out)\n",
    "        # [batch, height, width, depth_v]\n",
    "\n",
    "        if self.axis == 1:\n",
    "            # return to [batch, depth_v, height, width] for channels first\n",
    "            attn_out = K.permute_dimensions(attn_out, [0, 3, 1, 2])\n",
    "\n",
    "        return attn_out\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_shape = list(input_shape)\n",
    "        output_shape[self.axis] = self.depth_v\n",
    "        return tuple(output_shape)\n",
    "\n",
    "    def split_heads_2d(self, ip):\n",
    "        tensor_shape = K.shape(ip)\n",
    "\n",
    "        # batch, height, width, channels for axis = -1\n",
    "        tensor_shape = [tensor_shape[i] for i in range(len(self._shape))]\n",
    "\n",
    "        batch = tensor_shape[0]\n",
    "        height = tensor_shape[1]\n",
    "        width = tensor_shape[2]\n",
    "        channels = tensor_shape[3]\n",
    "\n",
    "        # Save the spatial tensor dimensions\n",
    "        self._batch = batch\n",
    "        self._height = height\n",
    "        self._width = width\n",
    "\n",
    "        ret_shape = K.stack([batch, height, width,  self.num_heads, channels // self.num_heads])\n",
    "        split = K.reshape(ip, ret_shape)\n",
    "        transpose_axes = (0, 3, 1, 2, 4)\n",
    "        split = K.permute_dimensions(split, transpose_axes)\n",
    "\n",
    "        return split\n",
    "\n",
    "    def relative_logits(self, q):\n",
    "        shape = K.shape(q)\n",
    "        # [batch, num_heads, H, W, depth_v]\n",
    "        shape = [shape[i] for i in range(5)]\n",
    "\n",
    "        height = shape[2]\n",
    "        width = shape[3]\n",
    "\n",
    "        rel_logits_w = self.relative_logits_1d(q, self.key_relative_w, height, width,\n",
    "                                               transpose_mask=[0, 1, 2, 4, 3, 5])\n",
    "\n",
    "        rel_logits_h = self.relative_logits_1d(\n",
    "            K.permute_dimensions(q, [0, 1, 3, 2, 4]),\n",
    "            self.key_relative_h, width, height,\n",
    "            transpose_mask=[0, 1, 4, 2, 5, 3])\n",
    "\n",
    "        return rel_logits_h, rel_logits_w\n",
    "\n",
    "    def relative_logits_1d(self, q, rel_k, H, W, transpose_mask):\n",
    "        rel_logits = tf.einsum('bhxyd,md->bhxym', q, rel_k)\n",
    "        rel_logits = K.reshape(rel_logits, [-1, self.num_heads * H, W, 2 * W - 1])\n",
    "        rel_logits = self.rel_to_abs(rel_logits)\n",
    "        rel_logits = K.reshape(rel_logits, [-1, self.num_heads, H, W, W])\n",
    "        rel_logits = K.expand_dims(rel_logits, axis=3)\n",
    "        rel_logits = K.tile(rel_logits, [1, 1, 1, H, 1, 1])\n",
    "        rel_logits = K.permute_dimensions(rel_logits, transpose_mask)\n",
    "        rel_logits = K.reshape(rel_logits, [-1, self.num_heads, H * W, H * W])\n",
    "        return rel_logits\n",
    "\n",
    "    def rel_to_abs(self, x):\n",
    "        shape = K.shape(x)\n",
    "        shape = [shape[i] for i in range(3)]\n",
    "        B, Nh, L, = shape\n",
    "        col_pad = K.zeros(K.stack([B, Nh, L, 1]))\n",
    "        x = K.concatenate([x, col_pad], axis=3)\n",
    "        flat_x = K.reshape(x, [B, Nh, L * 2 * L])\n",
    "        flat_pad = K.zeros(K.stack([B, Nh, L - 1]))\n",
    "        flat_x_padded = K.concatenate([flat_x, flat_pad], axis=2)\n",
    "        final_x = K.reshape(flat_x_padded, [B, Nh, L + 1, 2 * L - 1])\n",
    "        final_x = final_x[:, :, :L, L - 1:]\n",
    "        return final_x\n",
    "\n",
    "    def combine_heads_2d(self, inputs):\n",
    "        # [batch, num_heads, height, width, depth_v // num_heads]\n",
    "        transposed = K.permute_dimensions(inputs, [0, 2, 3, 1, 4])\n",
    "        # [batch, height, width, num_heads, depth_v // num_heads]\n",
    "        shape = K.shape(transposed)\n",
    "        shape = [shape[i] for i in range(5)]\n",
    "\n",
    "        a, b = shape[-2:]\n",
    "        ret_shape = K.stack(shape[:-2] + [a * b])\n",
    "        # [batch, height, width, depth_v]\n",
    "        return K.reshape(transposed, ret_shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'depth_k': self.depth_k,\n",
    "            'depth_v': self.depth_v,\n",
    "            'num_heads': self.num_heads,\n",
    "            'relative': self.relative,\n",
    "        }\n",
    "        base_config = super(AttentionAugmentation2D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "def augmented_conv1d(ip, shape, filters, kernel_size=3, strides=1, padding = 'same',\n",
    "                     depth_k=0.2, depth_v=0.2, num_heads=2, relative_encodings=True):\n",
    "    \"\"\"\n",
    "    Builds an Attention Augmented Convolution block.\n",
    "    Args:\n",
    "        ip: keras tensor.\n",
    "        filters: number of output filters.\n",
    "        kernel_size: convolution kernel size.\n",
    "        strides: strides of the convolution.\n",
    "        depth_k: float or int. Number of filters for k.\n",
    "            Computes the number of filters for `v`.\n",
    "            If passed as float, computed as `filters * depth_k`.\n",
    "        depth_v: float or int. Number of filters for v.\n",
    "            Computes the number of filters for `k`.\n",
    "            If passed as float, computed as `filters * depth_v`.\n",
    "        num_heads: int. Number of attention heads.\n",
    "            Must be set such that `depth_k // num_heads` is > 0.\n",
    "        relative_encodings: bool. Whether to use relative\n",
    "            encodings or not.\n",
    "    Returns:\n",
    "        a keras tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    if type(kernel_size) == int:\n",
    "        pass\n",
    "    else:\n",
    "        kernel_size = kernel_size[0]\n",
    "        \n",
    "    if type(strides) == int:\n",
    "        pass\n",
    "    else:\n",
    "        strides = strides[0]\n",
    "        \n",
    "    t_n = shape[0]\n",
    "    f_n = shape[1]\n",
    "        \n",
    "    # input_shape = K.int_shape(ip)\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    depth_k, depth_v = _normalize_depth_vars(depth_k, depth_v, filters)\n",
    "    \n",
    "    # print(kernel_size)\n",
    "    # print(strides)\n",
    "\n",
    "    conv_out = _conv_layer1d(ip, t_n, f_n, filters - depth_v, kernel_size, strides, padding = 'same')\n",
    "\n",
    "    # Augmented Attention Block\n",
    "    qkv_conv = _conv_layer1d(ip, t_n, f_n,  2 * depth_k + depth_v, 1, strides, padding = 'same')\n",
    "    attn_out = AttentionAugmentation2D(depth_k, depth_v, num_heads, relative_encodings)(qkv_conv)\n",
    "    attn_out = _conv_layer1r(attn_out, t_n, depth_v,  depth_v, 1, strides, padding = 'same')\n",
    "    \n",
    "    output = keras.layers.concatenate([conv_out, attn_out], axis=-1)\n",
    "#     output = Concatenate(axis=channel_axis)([conv_out, attn_out])\n",
    "   \n",
    "    reshape = Reshape((t_n, filters))(output)\n",
    "\n",
    "    return reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ece5b92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-24 17:50:29.464463: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-02-24 17:50:29.660691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:04:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2022-02-24 17:50:29.660972: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-02-24 17:50:29.663140: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-02-24 17:50:29.665298: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-02-24 17:50:29.665608: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-02-24 17:50:29.667907: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-02-24 17:50:29.669146: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-02-24 17:50:29.674020: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-02-24 17:50:29.680042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
      "2022-02-24 17:50:29.680426: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2022-02-24 17:50:29.697102: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400005000 Hz\n",
      "2022-02-24 17:50:29.699811: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fdcb8ae300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-02-24 17:50:29.699840: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-02-24 17:50:29.952499: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fdcdb8c420 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-02-24 17:50:29.952543: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN Xp, Compute Capability 6.1\n",
      "2022-02-24 17:50:29.955281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:04:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2022-02-24 17:50:29.955346: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-02-24 17:50:29.955369: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-02-24 17:50:29.955388: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-02-24 17:50:29.955406: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-02-24 17:50:29.955424: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-02-24 17:50:29.955442: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-02-24 17:50:29.955460: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-02-24 17:50:29.960457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
      "2022-02-24 17:50:29.960506: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-02-24 17:50:29.966671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-02-24 17:50:29.966689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
      "2022-02-24 17:50:29.966698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
      "2022-02-24 17:50:29.977308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11446 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:04:00.0, compute capability: 6.1)\n",
      "/home/ashutosh/anaconda3/envs/tensorgpu/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "import keras\n",
    "from keras.models import load_model\n",
    " \n",
    "# load model\n",
    "#model = load_model('data/model.h5')\n",
    "dependencies = {\n",
    "    'cindex_score': cindex_score,\n",
    "    'AttentionAugmentation2D': AttentionAugmentation2D\n",
    "}\n",
    "model = load_model('data/model.h5', custom_objects=dependencies)\n",
    "\n",
    "#from keras.utils import CustomObjectScope\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dafb4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_interaction_pairs(XD, XT,  Y, rows, cols):\n",
    "    drugs = []\n",
    "    targets = []\n",
    "    targetscls = []\n",
    "    affinity=[] \n",
    "\n",
    "    drug = XD[0]\n",
    "    drugs.append(drug)\n",
    "\n",
    "    target=XT[0]\n",
    "    targets.append(target)\n",
    "\n",
    "    drug_data = np.stack(drugs)\n",
    "    target_data = np.stack(targets)\n",
    "    return drug_data,target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7dec574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(predicted_labels)\n",
    "#def general_nfold_cv(XD, XT,  Y, label_row_inds, label_col_inds, prfmeasure, runmethod, FLAGS, labeled_sets, val_sets): ## BURAYA DA FLAGS LAZIM????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e1a544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "parser = argparse.ArgumentParser()\n",
    "# for model\n",
    "parser.add_argument(\n",
    "  '--seq_window_lengths',\n",
    "  type=int,\n",
    "  nargs='+',\n",
    "  help='Space seperated list of motif filter lengths. (ex, --window_lengths 4 8 12)'\n",
    ")\n",
    "parser.add_argument(\n",
    "  '--smi_window_lengths',\n",
    "  type=int,\n",
    "  nargs='+',\n",
    "  help='Space seperated list of motif filter lengths. (ex, --window_lengths 4 8 12)'\n",
    ")\n",
    "parser.add_argument(\n",
    "  '--num_windows',\n",
    "  type=int,\n",
    "  nargs='+',\n",
    "  help='Space seperated list of the number of motif filters corresponding to length list. (ex, --num_windows 100 200 100)'\n",
    ")\n",
    "parser.add_argument(\n",
    "  '--num_hidden',\n",
    "  type=int,\n",
    "  default=0,\n",
    "  help='Number of neurons in hidden layer.'\n",
    ")\n",
    "parser.add_argument(\n",
    "  '--num_classes',\n",
    "  type=int,\n",
    "  default=0,\n",
    "  help='Number of classes (families).'\n",
    ")\n",
    "parser.add_argument(\n",
    "  '--max_seq_len',\n",
    "  type=int,\n",
    "  default=0,\n",
    "  help='Length of input sequences.'\n",
    ")\n",
    "parser.add_argument(\n",
    "  '--max_smi_len',\n",
    "  type=int,\n",
    "  default=0,\n",
    "  help='Length of input sequences.'\n",
    ")\n",
    "# for learning\n",
    "parser.add_argument(\n",
    "  '--learning_rate',\n",
    "  type=float,\n",
    "  default=0.001,\n",
    "  help='Initial learning rate.'\n",
    ")\n",
    "parser.add_argument(\n",
    "  '--num_epoch',\n",
    "  type=int,\n",
    "  default=100,\n",
    "  help='Number of epochs to train.'\n",
    ")\n",
    "parser.add_argument(\n",
    "  '--batch_size',\n",
    "  type=int,\n",
    "  default=256,\n",
    "  help='Batch size. Must divide evenly into the dataset sizes.'\n",
    ")\n",
    "parser.add_argument(\n",
    "  '--dataset_path',\n",
    "  type=str,\n",
    "  default='data/kiba/',\n",
    "  help='Directory for input data.'\n",
    ")\n",
    "parser.add_argument(\n",
    "  '--problem_type',\n",
    "  type=int,\n",
    "  default=1,\n",
    "  help='Type of the prediction problem (1-4)'\n",
    ")\n",
    "parser.add_argument(\n",
    "  '--binary_th',\n",
    "  type=float,\n",
    "  default=0.0,\n",
    "  help='Threshold to split data into binary classes'\n",
    ")\n",
    "parser.add_argument(\n",
    "  '--is_log',\n",
    "  type=int,\n",
    "  default=0,\n",
    "  help='use log transformation for Y'\n",
    ")\n",
    "parser.add_argument(\n",
    "  '--checkpoint_path',\n",
    "  type=str,\n",
    "  default='',\n",
    "  help='Path to write checkpoint file.'\n",
    ")\n",
    "parser.add_argument(\n",
    "  '--log_dir',\n",
    "  type=str,\n",
    "  default='/tmp',\n",
    "  help='Directory for log data.'\n",
    ")\n",
    "FLAGS, unparsed = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87dd5391",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(object):\n",
    "  def __init__(self, fpath, setting_no, seqlen, smilen, need_shuffle = False):\n",
    "    self.SEQLEN = seqlen\n",
    "    self.SMILEN = smilen\n",
    "    #self.NCLASSES = n_classes\n",
    "    self.charseqset = CHARPROTSET\n",
    "    self.charseqset_size = CHARPROTLEN\n",
    "\n",
    "    self.charsmiset = CHARISOSMISET ###HERE CAN BE EDITED\n",
    "    self.charsmiset_size = CHARISOSMILEN\n",
    "    self.PROBLEMSET = setting_no\n",
    "\n",
    "    # read raw file\n",
    "    # self._raw = self.read_sets( FLAGS)\n",
    "\n",
    "    # iteration flags\n",
    "    # self._num_data = len(self._raw)\n",
    "\n",
    "\n",
    "  def read_sets(self, FLAGS): ### fpath should be the dataset folder /kiba/ or /davis/\n",
    "    fpath = FLAGS.dataset_path\n",
    "    setting_no = FLAGS.problem_type\n",
    "    print(\"Reading %s start\" % fpath)\n",
    "\n",
    "    test_fold = json.load(open(fpath + \"folds/test_fold_setting\" + str(setting_no)+\".txt\"))\n",
    "    train_folds = json.load(open(fpath + \"folds/train_fold_setting\" + str(setting_no)+\".txt\"))\n",
    "    \n",
    "    return test_fold, train_folds\n",
    "\n",
    "  def parse_data(self, FLAGS,  with_label=True, smileStr, proteinSeq): \n",
    "    fpath = FLAGS.dataset_path\t\n",
    "    print(\"Read %s start\" % fpath)\n",
    "\n",
    "    ligands = json.load(open(fpath+\"ligands_can.txt\"), object_pairs_hook=OrderedDict)\n",
    "    proteins = json.load(open(fpath+\"proteins.txt\"), object_pairs_hook=OrderedDict)\n",
    "\n",
    "    Y = pickle.load(open(fpath + \"Y\",\"rb\"), encoding='latin1') ### TODO: read from raw\n",
    "    if FLAGS.is_log:\n",
    "        Y = -(np.log10(Y/(math.pow(10,9))))\n",
    "\n",
    "    XD = []\n",
    "    XT = []\n",
    "\n",
    "    #smileStr = 'CC1CC=CC(=O)CCCCCC2=CC(=CC(=C2C(=O)O1)O)OC';\n",
    "    #proteinSeq = 'MTVKTEAAKGTLTYSRMRGMVAILIAFMKQRRMGLNDFIQKIANNSYACKHPEVQSILKISQPQEPELMNANPSPPPSPSQQINLGPSSNPHAKPSDFHFLKVIGKGSFGKVLLARHKAEEVFYAVKVLQKKAILKKKEEKHIMSERNVLLKNVKHPFLVGLHFSFQTADKLYFVLDYINGGELFYHLQRERCFLEPRARFYAAEIASALGYLHSLNIVYRDLKPENILLDSQGHIVLTDFGLCKENIEHNSTTSTFCGTPEYLAPEVLHKQPYDRTVDWWCLGAVLYEMLYGLPPFYSRNTAEMYDNILNKPLQLKPNITNSARHLLEGLLQKDRTKRLGAKDDFMEIKSHVFFSLINWDDLINKKITPPFNPNVSGPNDLRHFDPEFTEEPVPNSIGKSPDSVLVTASVKEAAEAFLGFSYAPPTDSFL';\n",
    "#     print(type(ligands.keys()))\n",
    "#     sys.exit()\n",
    "    if with_label:\n",
    "#     for d in ligands.keys():\n",
    "            XD.append(label_smiles(smileStr, self.SMILEN, self.charsmiset))\n",
    "            XT.append(label_sequence(proteinSeq, self.SEQLEN, self.charseqset))\n",
    "    else:\n",
    "            XD.append(one_hot_smiles(smileStr, self.SMILEN, self.charsmiset))\n",
    "            XT.append(one_hot_sequence(proteinSeq, self.SEQLEN, self.charseqset))\n",
    "  \n",
    "    return XD, XT, Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba458a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARPROTSET = { \"A\": 1, \"C\": 2, \"B\": 3, \"E\": 4, \"D\": 5, \"G\": 6, \n",
    "\t\t\t\t\"F\": 7, \"I\": 8, \"H\": 9, \"K\": 10, \"M\": 11, \"L\": 12, \n",
    "\t\t\t\t\"O\": 13, \"N\": 14, \"Q\": 15, \"P\": 16, \"S\": 17, \"R\": 18, \n",
    "\t\t\t\t\"U\": 19, \"T\": 20, \"W\": 21, \n",
    "\t\t\t\t\"V\": 22, \"Y\": 23, \"X\": 24, \n",
    "\t\t\t\t\"Z\": 25 }\n",
    "\n",
    "CHARPROTLEN = 25\n",
    "\n",
    "CHARCANSMISET = { \"#\": 1, \"%\": 2, \")\": 3, \"(\": 4, \"+\": 5, \"-\": 6, \n",
    "\t\t\t \".\": 7, \"1\": 8, \"0\": 9, \"3\": 10, \"2\": 11, \"5\": 12, \n",
    "\t\t\t \"4\": 13, \"7\": 14, \"6\": 15, \"9\": 16, \"8\": 17, \"=\": 18, \n",
    "\t\t\t \"A\": 19, \"C\": 20, \"B\": 21, \"E\": 22, \"D\": 23, \"G\": 24,\n",
    "\t\t\t \"F\": 25, \"I\": 26, \"H\": 27, \"K\": 28, \"M\": 29, \"L\": 30, \n",
    "\t\t\t \"O\": 31, \"N\": 32, \"P\": 33, \"S\": 34, \"R\": 35, \"U\": 36, \n",
    "\t\t\t \"T\": 37, \"W\": 38, \"V\": 39, \"Y\": 40, \"[\": 41, \"Z\": 42, \n",
    "\t\t\t \"]\": 43, \"_\": 44, \"a\": 45, \"c\": 46, \"b\": 47, \"e\": 48, \n",
    "\t\t\t \"d\": 49, \"g\": 50, \"f\": 51, \"i\": 52, \"h\": 53, \"m\": 54, \n",
    "\t\t\t \"l\": 55, \"o\": 56, \"n\": 57, \"s\": 58, \"r\": 59, \"u\": 60,\n",
    "\t\t\t \"t\": 61, \"y\": 62}\n",
    "\n",
    "CHARCANSMILEN = 62\n",
    "\n",
    "CHARISOSMISET = {\"#\": 29, \"%\": 30, \")\": 31, \"(\": 1, \"+\": 32, \"-\": 33, \"/\": 34, \".\": 2, \n",
    "\t\t\t\t\"1\": 35, \"0\": 3, \"3\": 36, \"2\": 4, \"5\": 37, \"4\": 5, \"7\": 38, \"6\": 6, \n",
    "\t\t\t\t\"9\": 39, \"8\": 7, \"=\": 40, \"A\": 41, \"@\": 8, \"C\": 42, \"B\": 9, \"E\": 43, \n",
    "\t\t\t\t\"D\": 10, \"G\": 44, \"F\": 11, \"I\": 45, \"H\": 12, \"K\": 46, \"M\": 47, \"L\": 13, \n",
    "\t\t\t\t\"O\": 48, \"N\": 14, \"P\": 15, \"S\": 49, \"R\": 16, \"U\": 50, \"T\": 17, \"W\": 51, \n",
    "\t\t\t\t\"V\": 18, \"Y\": 52, \"[\": 53, \"Z\": 19, \"]\": 54, \"\\\\\": 20, \"a\": 55, \"c\": 56, \n",
    "\t\t\t\t\"b\": 21, \"e\": 57, \"d\": 22, \"g\": 58, \"f\": 23, \"i\": 59, \"h\": 24, \"m\": 60, \n",
    "\t\t\t\t\"l\": 25, \"o\": 61, \"n\": 26, \"s\": 62, \"r\": 27, \"u\": 63, \"t\": 28, \"y\": 64}\n",
    "\n",
    "CHARISOSMILEN = 64\n",
    "def one_hot_smiles(line, MAX_SMI_LEN, smi_ch_ind):\n",
    "\tX = np.zeros((MAX_SMI_LEN, len(smi_ch_ind))) #+1\n",
    "\n",
    "\tfor i, ch in enumerate(line[:MAX_SMI_LEN]):\n",
    "\t\tX[i, (smi_ch_ind[ch]-1)] = 1 \n",
    "\n",
    "\treturn X #.tolist()\n",
    "\n",
    "def one_hot_sequence(line, MAX_SEQ_LEN, smi_ch_ind):\n",
    "\tX = np.zeros((MAX_SEQ_LEN, len(smi_ch_ind))) \n",
    "\tfor i, ch in enumerate(line[:MAX_SEQ_LEN]):\n",
    "\t\tX[i, (smi_ch_ind[ch])-1] = 1\n",
    "\n",
    "\treturn X #.tolist()\n",
    "\n",
    "\n",
    "def label_smiles(line, MAX_SMI_LEN, smi_ch_ind):\n",
    "\tX = np.zeros(MAX_SMI_LEN)\n",
    "\tfor i, ch in enumerate(line[:MAX_SMI_LEN]): #\tx, smi_ch_ind, y\n",
    "\t\tX[i] = smi_ch_ind[ch]\n",
    "\n",
    "\treturn X #.tolist()\n",
    "\n",
    "def label_sequence(line, MAX_SEQ_LEN, smi_ch_ind):\n",
    "\tX = np.zeros(MAX_SEQ_LEN)\n",
    "\n",
    "\tfor i, ch in enumerate(line[:MAX_SEQ_LEN]):\n",
    "\t\tX[i] = smi_ch_ind[ch]\n",
    "\n",
    "\treturn X #.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "392fcf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS.num_windows = [32]\n",
    "FLAGS.smi_window_lengths = [4, 8]\n",
    "FLAGS.seq_window_lengths = [8, 12]\n",
    "FLAGS.num_epoch = 200\n",
    "FLAGS.batch_size = 64\n",
    "FLAGS.max_seq_len  = 1000\n",
    "FLAGS.max_smi_len = 100\n",
    "FLAGS.problem_type = 2\n",
    "FLAGS.log_dir  = \"logs/\"\n",
    "dataset = DataSet( fpath = FLAGS.dataset_path, ### BUNU ARGS DA GUNCELLE\n",
    "                  setting_no = FLAGS.problem_type, ##BUNU ARGS A EKLE\n",
    "                  seqlen = FLAGS.max_seq_len,\n",
    "                  smilen = FLAGS.max_smi_len,\n",
    "                  need_shuffle = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f9f050d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data/kiba/ start\n",
      "Reading data/kiba/ start\n",
      "-----Setting 2 test-------\n"
     ]
    }
   ],
   "source": [
    "import sys, re, math, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "import collections\n",
    "from collections import OrderedDict\n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "XD, XT, Y = dataset.parse_data(FLAGS)\n",
    "test_set, outer_train_sets = dataset.read_sets(FLAGS) \n",
    "print('-----Setting 2 test-------')\n",
    "x = outer_train_sets\n",
    "train_sets = []\n",
    "val_sets = []\n",
    "r1 = int(0.9 * len(x))\n",
    "x1 = x[0:r1]\n",
    "x3 = x[r1:]\n",
    "train_sets.append(x1)\n",
    "val_sets.append(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c498183f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42. 42. 35. 42. 42. 40. 42. 42.  1. 40. 48. 31. 42. 42. 42. 42. 42. 42.\n",
      "   4. 40. 42. 42.  1. 40. 42. 42.  1. 40. 42.  4. 42.  1. 40. 48. 31. 48.\n",
      "  35. 31. 48. 31. 48. 42.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "foldind = 0 # folding is just index of the fold\n",
    "valinds = val_sets[foldind]\n",
    "label_row_inds, label_col_inds = np.where(np.isnan(Y)==False)  #basically finds the point address of affinity [x,y]\n",
    "terows = label_row_inds[valinds]\n",
    "tecols = label_col_inds[valinds]\n",
    "val_drugs, val_prots = prepare_interaction_pairs(XD, XT,  Y, terows, tecols)\n",
    "# val_drugs, val_prots, val_Y = prepare_interaction_pairs(XD, XT,  Y, terows, tecols)\n",
    "print(val_drugs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "628aefc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. 11. 20. 22. 10. 20.\n",
      "   4.  1.  1. 10.  6. 20. 12. 20. 23. 17. 18. 11. 18.  6. 11. 22.  1.  8.\n",
      "  12.  8.  1.  7. 11. 10. 15. 18. 18. 11.  6. 12. 14.  5.  7.  8. 15. 10.\n",
      "   8.  1. 14. 14. 17. 23.  1.  2. 10.  9. 16.  4. 22. 15. 17.  8. 12. 10.\n",
      "   8. 17. 15. 16. 15.  4. 16.  4. 12. 11. 14.  1. 14. 16. 17. 16. 16. 16.\n",
      "  17. 16. 17. 15. 15.  8. 14. 12.  6. 16. 17. 17. 14. 16.  9.  1. 10. 16.\n",
      "  17.  5.  7.  9.  7. 12. 10. 22.  8.  6. 10.  6. 17.  7.  6. 10. 22. 12.\n",
      "  12.  1. 18.  9. 10.  1.  4.  4. 22.  7. 23.  1. 22. 10. 22. 12. 15. 10.\n",
      "  10.  1.  8. 12. 10. 10. 10.  4.  4. 10.  9.  8. 11. 17.  4. 18. 14. 22.\n",
      "  12. 12. 10. 14. 22. 10.  9. 16.  7. 12. 22.  6. 12.  9.  7. 17.  7. 15.\n",
      "  20.  1.  5. 10. 12. 23.  7. 22. 12.  5. 23.  8. 14.  6.  6.  4. 12.  7.\n",
      "  23.  9. 12. 15. 18.  4. 18.  2.  7. 12.  4. 16. 18.  1. 18.  7. 23.  1.\n",
      "   1.  4.  8.  1. 17.  1. 12.  6. 23. 12.  9. 17. 12. 14.  8. 22. 23. 18.\n",
      "   5. 12. 10. 16.  4. 14.  8. 12. 12.  5. 17. 15.  6.  9.  8. 22. 12. 20.\n",
      "   5.  7.  6. 12.  2. 10.  4. 14.  8.  4.  9. 14. 17. 20. 20. 17. 20.  7.\n",
      "   2.  6. 20. 16.  4. 23. 12.  1. 16.  4. 22. 12.  9. 10. 15. 16. 23.  5.\n",
      "  18. 20. 22.  5. 21. 21.  2. 12.  6.  1. 22. 12. 23.  4. 11. 12. 23.  6.\n",
      "  12. 16. 16.  7. 23. 17. 18. 14. 20.  1.  4. 11. 23.  5. 14.  8. 12. 14.\n",
      "  10. 16. 12. 15. 12. 10. 16. 14.  8. 20. 14. 17.  1. 18.  9. 12. 12.  4.\n",
      "   6. 12. 12. 15. 10.  5. 18. 20. 10. 18. 12.  6.  1. 10.  5.  5.  7. 11.\n",
      "   4.  8. 10. 17.  9. 22.  7.  7. 17. 12.  8. 14. 21.  5.  5. 12.  8. 14.\n",
      "  10. 10.  8. 20. 16. 16.  7. 14. 16. 14. 22. 17.  6. 16. 14.  5. 12. 18.\n",
      "   9.  7.  5. 16.  4.  7. 20.  4.  4. 16. 22. 16. 14. 17.  8.  6. 10. 17.\n",
      "  16.  5. 17. 22. 12. 22. 20.  1. 17. 22. 10.  4.  1.  1.  4.  1.  7. 12.\n",
      "   6.  7. 17. 23.  1. 16. 16. 20.  5. 17.  7. 12.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "#XD and XT is empty. findout please\n",
    "print(val_prots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cfd441f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 100, 128)     8320        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1000, 128)    3328        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 98, 64)       24640       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 998, 64)      24640       embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 96, 128)      24704       conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 996, 128)     24704       conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 96, 12)       1548        conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 996, 30)      3870        conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 96, 1, 12)    0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)            (None, 996, 1, 30)   0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_augmentation2d_3 (Att (None, 96, 1, 4)     384         reshape_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_augmentation2d_4 (Att (None, 996, 1, 10)   3984        reshape_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 96, 4)        0           attention_augmentation2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_18 (Reshape)            (None, 996, 10)      0           attention_augmentation2d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 96, 188)      72380       conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 96, 4)        20          reshape_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 996, 182)     70070       conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 996, 10)      110         reshape_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 96, 1, 188)   0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 96, 1, 4)     0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)            (None, 996, 1, 182)  0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_19 (Reshape)            (None, 996, 1, 10)   0           conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 96, 1, 192)   0           reshape_11[0][0]                 \n",
      "                                                                 reshape_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 996, 1, 192)  0           reshape_16[0][0]                 \n",
      "                                                                 reshape_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 96, 192)      0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_20 (Reshape)            (None, 996, 192)     0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 192)          0           reshape_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 192)          0           reshape_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 384)          0           global_max_pooling1d_3[0][0]     \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1024)         394240      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024)         0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1024)         1049600     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1024)         0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 512)          524800      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            513         dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,231,855\n",
      "Trainable params: 2,231,855\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15dd1740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-24 17:50:36.306737: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-02-24 17:50:36.463345: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-02-24 17:50:37.130832: W tensorflow/stream_executor/gpu/redzone_allocator.cc:312] Not found: ./bin/ptxas not found\n",
      "Relying on driver to perform ptx compilation. This message will be only logged once.\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = model.predict([np.array(val_drugs), np.array(val_prots)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "012f5710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.307234]]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca6cfcb",
   "metadata": {},
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6582cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(val_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2453141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, rperf2 = model.evaluate(([np.array(val_drugs),np.array(val_prots) ]), np.array(val_Y), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735e3271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b771ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rperf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537d05ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(predicted_labels.tolist())\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43da4d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
